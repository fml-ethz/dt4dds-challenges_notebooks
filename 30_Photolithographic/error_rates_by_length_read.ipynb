{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import plotly.graph_objects as pg\n",
    "from plotly.subplots import make_subplots\n",
    "import statsmodels.stats.descriptivestats as ds\n",
    "\n",
    "import dt4dds.analysis.dataaggregation as analysis\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_colors = {\n",
    "    'substitutions': '#e6550d',\n",
    "    'insertions': '#3182bd',\n",
    "    'deletions': '#756bb1'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = analysis.GroupAnalysis([\n",
    "    ('Lietard_Normal', analysis.ErrorAnalysis(\"../data_experimental/Photolithographic_Lietard/normal/analysis\", local=True, paired=False)),\n",
    "    ('Lietard_Capped', analysis.ErrorAnalysis(\"../data_experimental/Photolithographic_Lietard/capped/analysis\", local=True, paired=False)),\n",
    "    ('Lietard_Spaced', analysis.ErrorAnalysis(\"../data_experimental/Photolithographic_Lietard/spaced/analysis\", local=True, paired=False)),\n",
    "    ('Lietard_highdensity', analysis.ErrorAnalysis(\"../data_experimental/Photolithographic_Lietard/high_density/analysis\", local=True, paired=False)),\n",
    "    ('Antkowiak_File1', analysis.ErrorAnalysis(\"../data_experimental/Photolithographic_Antkowiak/File1/analysis\", local=True, paired=False)),\n",
    "])\n",
    "order = ['Lietard_Normal', 'Lietard_Capped', 'Lietard_Spaced', 'Lietard_highdensity', 'Antkowiak_File1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Median error rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_error_rates = {}\n",
    "\n",
    "for errortype in ['substitutions', 'insertions', 'deletions']:\n",
    "    \n",
    "    idata = data.data[f'{errortype}_by_refposition'].copy()\n",
    "\n",
    "    for group in idata.group.unique():\n",
    "        group_data = idata[idata.group == group]\n",
    "        mean_error_rates[(errortype, group)] = group_data.rate.median()\n",
    "\n",
    "mean_error_rates = pd.Series(mean_error_rates).to_frame('rate').reset_index(names=['errortype', 'group'])\n",
    "\n",
    "# average over the experiments across error types\n",
    "def summary(group):\n",
    "    d = {}\n",
    "    stats = ds.describe(group.rate)\n",
    "    d['mean'] = stats.loc['mean', 'rate']\n",
    "    d['std'] = stats.loc['std_err', 'rate']\n",
    "    return pd.Series(d, index=['mean', 'std'])\n",
    "mean_error_rates = mean_error_rates.groupby(['errortype'], as_index=False).apply(summary, include_groups=False)\n",
    "\n",
    "mean_error_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Median rates of error events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_error_event_rates = {}\n",
    "\n",
    "for errortype in ['substitutions', 'insertions', 'deletions']:\n",
    "    \n",
    "    idata = data.data[f'{errortype}_by_refposition'].copy()\n",
    "\n",
    "    for group in idata.group.unique():\n",
    "        group_data = idata[idata.group == group]\n",
    "        mean_error_rate = group_data.rate.median()\n",
    "\n",
    "        # calculate the mean length per event\n",
    "        lengths = data.data[f\"error_frequency_by_length\"]\n",
    "        lengths = lengths[lengths.group == group].copy()\n",
    "        lengths = lengths[lengths['type'] == 'substitutions'].groupby('length')['value'].mean()\n",
    "        mean_length = np.sum(lengths.index * lengths) / np.sum(lengths)\n",
    "\n",
    "        # get the mean error event rate\n",
    "        mean_error_event_rates[(errortype, group)] = mean_error_rate / mean_length\n",
    "\n",
    "mean_error_event_rates = pd.Series(mean_error_event_rates).to_frame('rate').reset_index(names=['errortype', 'group'])\n",
    "\n",
    "# average over the experiments across error types\n",
    "def summary(group):\n",
    "    d = {}\n",
    "    stats = ds.describe(group.rate)\n",
    "    d['mean'] = stats.loc['mean', 'rate']\n",
    "    d['std'] = stats.loc['std_err', 'rate']\n",
    "    return pd.Series(d, index=['mean', 'std'])\n",
    "mean_error_event_rates = mean_error_event_rates.groupby(['errortype'], as_index=False).apply(summary, include_groups=False)\n",
    "\n",
    "mean_error_event_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consecutive errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 4\n",
    "\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2, \n",
    "    shared_xaxes=True, \n",
    "    vertical_spacing=0.05,\n",
    "    row_heights=[0.3, 0.7],\n",
    ")\n",
    "\n",
    "# get data for errors by length\n",
    "idata = data.data[f\"error_frequency_by_length\"].copy()\n",
    "\n",
    "# clip to maximum length, sum up all errors with length >= MAX_LENGTH\n",
    "idata.length = idata.length.clip(upper=MAX_LENGTH)\n",
    "newframe = idata.loc[idata.length == MAX_LENGTH].groupby(['type', 'exp', 'read', 'group'])['value'].sum().reset_index().copy()\n",
    "newframe['length'] = MAX_LENGTH\n",
    "idata.drop(idata.loc[idata['length'] == MAX_LENGTH].index, inplace=True)\n",
    "idata = pd.concat([idata, newframe], ignore_index=True)\n",
    "\n",
    "# average over the experiments across error types\n",
    "def summary(group):\n",
    "    d = {}\n",
    "    stats = ds.describe(group.value)\n",
    "    d['mean'] = stats.loc['mean', 'value']\n",
    "    d['std'] = stats.loc['std_err', 'value']\n",
    "    return pd.Series(d, index=['mean', 'std'])\n",
    "df_aggregate = idata.groupby(['type', 'length'], as_index=False).apply(summary, include_groups=False)\n",
    "\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2, \n",
    "    shared_xaxes=True, \n",
    "    vertical_spacing=0.05,\n",
    "    row_heights=[0.3, 0.7],\n",
    ")\n",
    "\n",
    "for error_type in ['substitutions', 'insertions', 'deletions']:\n",
    "    this_data = df_aggregate.loc[df_aggregate['type'] == error_type].copy()\n",
    "    fig.add_trace(\n",
    "        pg.Bar(\n",
    "            x=this_data['length'],\n",
    "            y=this_data['mean'],\n",
    "            error_y=dict(\n",
    "                type='data',\n",
    "                array=this_data['std'],\n",
    "                color='#222222',\n",
    "                visible=True,\n",
    "                thickness=1.5,\n",
    "            ),\n",
    "            marker_color=error_colors[error_type]\n",
    "        ),\n",
    "        col=1,\n",
    "        row=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        pg.Bar(\n",
    "            x=this_data['length'],\n",
    "            y=this_data['mean'],\n",
    "            error_y=dict(\n",
    "                type='data',\n",
    "                array=this_data['std'],\n",
    "                color='#222222',\n",
    "                visible=True,\n",
    "                thickness=1.5,\n",
    "            ),\n",
    "            marker_color=error_colors[error_type]\n",
    "        ),\n",
    "        col=1,\n",
    "        row=2\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    template='simple_white',\n",
    "    height=200,\n",
    "    width=250,\n",
    "    showlegend=False,\n",
    "    barmode='group',\n",
    "    margin=dict(l=50, r=0, t=5, b=0),\n",
    "    font_family=\"Inter\",\n",
    "    legend_font_size=28/3,\n",
    ")\n",
    "\n",
    "ticktext = list(map(str, range(1, MAX_LENGTH+1)))\n",
    "ticktext[-1] += '+'\n",
    "\n",
    "fig.update_xaxes(\n",
    "    showticklabels=False, \n",
    "    visible=False, \n",
    "    range=[0.5, MAX_LENGTH+0.5],\n",
    "    tickmode='array',\n",
    "    tickvals=list(range(1, MAX_LENGTH+1)),\n",
    "    ticktext=ticktext,\n",
    ")\n",
    "fig.update_xaxes(title=\"Length of consecutive errors\", showticklabels=True, visible=True, row=2, col=1)\n",
    "fig.update_xaxes(showticklabels=True, visible=True, row=2, col=2)\n",
    "\n",
    "fig.update_yaxes(tickformat=\",.0%\")\n",
    "fig.update_yaxes(title=\"Fraction of errors\", range=[0, 0.17], row=2, dtick=0.05, minor_dtick=0.025)\n",
    "fig.update_yaxes(range=[0.725, 1.0], row=1, dtick=0.2, minor_dtick=0.1)\n",
    "\n",
    "fig = plotting.standardize_plot(fig)\n",
    "fig.show()\n",
    "fig.write_image(\"./figures/error_distribution_by_length.svg\")\n",
    "\n",
    "\n",
    "# compare to the theoretical model of geometric distribution\n",
    "df_aggregate['theory'] = 0.0\n",
    "for errortype in mean_error_rates.errortype.unique():\n",
    "    ratios = scipy.stats.geom.pmf(np.arange(1, MAX_LENGTH+1), 1-mean_error_rates.loc[mean_error_rates.errortype == errortype, 'mean'])\n",
    "    ratios[-1] = 1-np.sum(ratios[0:-1])\n",
    "    df_aggregate.loc[(df_aggregate['type'] == errortype) & (df_aggregate['length'] <= MAX_LENGTH), 'theory'] = ratios\n",
    "df_aggregate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Errors per read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ERRORS = 6\n",
    "N_BASES_PER_READ = 60\n",
    "\n",
    "# get data for errors by read\n",
    "idata = data.data[f\"error_frequency_by_read\"].copy()\n",
    "idata = idata.loc[idata.type.isin(['substitutions', 'insertions', 'deletions'])]\n",
    "\n",
    "# clip to maximum number, sum up all errors with length >= MAX_ERRORS\n",
    "idata.frequency = idata.frequency.clip(upper=MAX_ERRORS)\n",
    "newframe = idata.loc[idata.frequency == MAX_ERRORS].groupby(['type', 'exp', 'read', 'group'])['value'].sum().reset_index()\n",
    "newframe['frequency'] = MAX_ERRORS\n",
    "idata.drop(idata.loc[idata['frequency'] == MAX_ERRORS].index, inplace=True)\n",
    "idata = pd.concat([idata, newframe], ignore_index=True)\n",
    "\n",
    "# average over the experiments across error types\n",
    "def summary(group):\n",
    "    d = {}\n",
    "    stats = ds.describe(group.value)\n",
    "    d['mean'] = stats.loc['mean', 'value']\n",
    "    d['std'] = stats.loc['std_err', 'value']\n",
    "    return pd.Series(d, index=['mean', 'std'])\n",
    "df_aggregate = idata.groupby(['type', 'frequency'], as_index=False).apply(summary, include_groups=False)\n",
    "\n",
    "\n",
    "fig = pg.Figure()\n",
    "\n",
    "for error_type in ['substitutions', 'insertions', 'deletions']:\n",
    "\n",
    "    this_data = df_aggregate.loc[df_aggregate['type'] == error_type].copy()\n",
    "    fig.add_trace(\n",
    "        pg.Bar(\n",
    "            x=this_data['frequency'],\n",
    "            y=this_data['mean'],\n",
    "            error_y=dict(\n",
    "                type='data',\n",
    "                array=this_data['std'],\n",
    "                color='#222222',\n",
    "                visible=True,\n",
    "                thickness=1.5,\n",
    "            ),\n",
    "            marker_color=error_colors[error_type]\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    template='simple_white',\n",
    "    height=200,\n",
    "    width=400,\n",
    "    showlegend=False,\n",
    "    barmode='group',\n",
    "    margin=dict(l=50, r=0, t=5, b=0),\n",
    "    font_family=\"Inter\",\n",
    "    legend_font_size=28/3,\n",
    ")\n",
    "\n",
    "ticktext = list(map(str, range(0, MAX_ERRORS+1)))\n",
    "ticktext[-1] += '+'\n",
    "\n",
    "fig.update_xaxes(\n",
    "    title=\"Number of errors in read\",\n",
    "    range=[-0.5, MAX_ERRORS+0.5],\n",
    "    tickmode = 'array',\n",
    "    tickvals = list(range(0, MAX_ERRORS+1)),\n",
    "    ticktext = ticktext,\n",
    ")\n",
    "\n",
    "fig.update_yaxes(\n",
    "    title=\"Fraction of reads\", \n",
    "    tickformat=\",.0%\", \n",
    "    range=[0, 0.65], \n",
    "    dtick=0.25,\n",
    "    title_font_family=\"Inter\",\n",
    "    title_font_size=28/3, \n",
    "    tickfont_size=28/3\n",
    ")\n",
    "\n",
    "fig = plotting.standardize_plot(fig)\n",
    "fig.show()\n",
    "fig.write_image(\"./figures/error_distribution_by_read.svg\")\n",
    "\n",
    "\n",
    "# compare to the theoretical model of geometric distribution\n",
    "df_aggregate['theory'] = 0.0\n",
    "for errortype in mean_error_event_rates.errortype.unique():\n",
    "    ratios = scipy.stats.binom.pmf(np.arange(0, MAX_ERRORS+1), N_BASES_PER_READ, mean_error_event_rates.loc[mean_error_event_rates.errortype == errortype, 'mean'])\n",
    "    ratios[-1] = 1-np.sum(ratios[0:-1])\n",
    "    df_aggregate.loc[(df_aggregate['type'] == errortype) & (df_aggregate['frequency'] <= MAX_ERRORS), 'theory'] = ratios\n",
    "df_aggregate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redo for simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = analysis.GroupAnalysis([\n",
    "    ('simulated_simulated', analysis.ErrorAnalysis(\"../data_simulated/test_photolithography/analysis\", local=True, paired=False)),\n",
    "])\n",
    "order = ['simulated_simulated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_error_rates = {}\n",
    "\n",
    "for errortype in ['substitutions', 'insertions', 'deletions']:\n",
    "    \n",
    "    idata = data.data[f'{errortype}_by_refposition'].copy()\n",
    "\n",
    "    for group in idata.group.unique():\n",
    "        group_data = idata[idata.group == group]\n",
    "        mean_error_rates[(errortype, group)] = group_data.rate.median()\n",
    "\n",
    "mean_error_rates = pd.Series(mean_error_rates).to_frame('rate').reset_index(names=['errortype', 'group'])\n",
    "\n",
    "# average over the experiments across error types\n",
    "def summary(group):\n",
    "    d = {}\n",
    "    stats = ds.describe(group.rate)\n",
    "    d['mean'] = stats.loc['mean', 'rate']\n",
    "    d['std'] = stats.loc['std_err', 'rate']\n",
    "    return pd.Series(d, index=['mean', 'std'])\n",
    "mean_error_rates = mean_error_rates.groupby(['errortype'], as_index=False).apply(summary, include_groups=False)\n",
    "\n",
    "mean_error_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_error_event_rates = {}\n",
    "\n",
    "for errortype in ['substitutions', 'insertions', 'deletions']:\n",
    "    \n",
    "    idata = data.data[f'{errortype}_by_refposition'].copy()\n",
    "\n",
    "    for group in idata.group.unique():\n",
    "        group_data = idata[idata.group == group]\n",
    "        mean_error_rate = group_data.rate.median()\n",
    "\n",
    "        # calculate the mean length per event\n",
    "        lengths = data.data[f\"error_frequency_by_length\"]\n",
    "        lengths = lengths[lengths.group == group].copy()\n",
    "        lengths = lengths[lengths['type'] == 'substitutions'].groupby('length')['value'].mean()\n",
    "        mean_length = np.sum(lengths.index * lengths) / np.sum(lengths)\n",
    "\n",
    "        # get the mean error event rate\n",
    "        mean_error_event_rates[(errortype, group)] = mean_error_rate / mean_length\n",
    "\n",
    "mean_error_event_rates = pd.Series(mean_error_event_rates).to_frame('rate').reset_index(names=['errortype', 'group'])\n",
    "\n",
    "# average over the experiments across error types\n",
    "def summary(group):\n",
    "    d = {}\n",
    "    stats = ds.describe(group.rate)\n",
    "    d['mean'] = stats.loc['mean', 'rate']\n",
    "    d['std'] = stats.loc['std_err', 'rate']\n",
    "    return pd.Series(d, index=['mean', 'std'])\n",
    "mean_error_event_rates = mean_error_event_rates.groupby(['errortype'], as_index=False).apply(summary, include_groups=False)\n",
    "\n",
    "mean_error_event_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 4\n",
    "\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2, \n",
    "    shared_xaxes=True, \n",
    "    vertical_spacing=0.05,\n",
    "    row_heights=[0.3, 0.7],\n",
    ")\n",
    "\n",
    "# get data for errors by length\n",
    "idata = data.data[f\"error_frequency_by_length\"].copy()\n",
    "\n",
    "# clip to maximum length, sum up all errors with length >= MAX_LENGTH\n",
    "idata.length = idata.length.clip(upper=MAX_LENGTH)\n",
    "newframe = idata.loc[idata.length == MAX_LENGTH].groupby(['type', 'exp', 'read', 'group'])['value'].sum().reset_index().copy()\n",
    "newframe['length'] = MAX_LENGTH\n",
    "idata.drop(idata.loc[idata['length'] == MAX_LENGTH].index, inplace=True)\n",
    "idata = pd.concat([idata, newframe], ignore_index=True)\n",
    "\n",
    "# average over the experiments across error types\n",
    "def summary(group):\n",
    "    d = {}\n",
    "    stats = ds.describe(group.value)\n",
    "    d['mean'] = stats.loc['mean', 'value']\n",
    "    d['std'] = stats.loc['std_err', 'value']\n",
    "    return pd.Series(d, index=['mean', 'std'])\n",
    "df_aggregate = idata.groupby(['type', 'length'], as_index=False).apply(summary, include_groups=False)\n",
    "\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2, \n",
    "    shared_xaxes=True, \n",
    "    vertical_spacing=0.05,\n",
    "    row_heights=[0.3, 0.7],\n",
    ")\n",
    "\n",
    "for error_type in ['substitutions', 'insertions', 'deletions']:\n",
    "    this_data = df_aggregate.loc[df_aggregate['type'] == error_type].copy()\n",
    "    fig.add_trace(\n",
    "        pg.Bar(\n",
    "            x=this_data['length'],\n",
    "            y=this_data['mean'],\n",
    "            marker_color=error_colors[error_type]\n",
    "        ),\n",
    "        col=1,\n",
    "        row=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        pg.Bar(\n",
    "            x=this_data['length'],\n",
    "            y=this_data['mean'],\n",
    "            marker_color=error_colors[error_type]\n",
    "        ),\n",
    "        col=1,\n",
    "        row=2\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    template='simple_white',\n",
    "    height=200,\n",
    "    width=250,\n",
    "    showlegend=False,\n",
    "    barmode='group',\n",
    "    margin=dict(l=50, r=0, t=5, b=0),\n",
    "    font_family=\"Inter\",\n",
    "    legend_font_size=28/3,\n",
    ")\n",
    "\n",
    "ticktext = list(map(str, range(1, MAX_LENGTH+1)))\n",
    "ticktext[-1] += '+'\n",
    "\n",
    "fig.update_xaxes(\n",
    "    showticklabels=False, \n",
    "    visible=False, \n",
    "    range=[0.5, MAX_LENGTH+0.5],\n",
    "    tickmode='array',\n",
    "    tickvals=list(range(1, MAX_LENGTH+1)),\n",
    "    ticktext=ticktext,\n",
    ")\n",
    "fig.update_xaxes(title=\"Length of consecutive errors\", showticklabels=True, visible=True, row=2, col=1)\n",
    "fig.update_xaxes(showticklabels=True, visible=True, row=2, col=2)\n",
    "\n",
    "fig.update_yaxes(tickformat=\",.0%\")\n",
    "fig.update_yaxes(title=\"Fraction of errors\", range=[0, 0.17], row=2, dtick=0.05, minor_dtick=0.025)\n",
    "fig.update_yaxes(range=[0.725, 1.0], row=1, dtick=0.2, minor_dtick=0.1)\n",
    "\n",
    "fig = plotting.standardize_plot(fig)\n",
    "fig.show()\n",
    "fig.write_image(\"./SI_figures/error_distribution_by_length.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ERRORS = 6\n",
    "N_BASES_PER_READ = 60\n",
    "\n",
    "# get data for errors by read\n",
    "idata = data.data[f\"error_frequency_by_read\"].copy()\n",
    "idata = idata.loc[idata.type.isin(['substitutions', 'insertions', 'deletions'])]\n",
    "\n",
    "# clip to maximum number, sum up all errors with length >= MAX_ERRORS\n",
    "idata.frequency = idata.frequency.clip(upper=MAX_ERRORS)\n",
    "newframe = idata.loc[idata.frequency == MAX_ERRORS].groupby(['type', 'exp', 'read', 'group'])['value'].sum().reset_index()\n",
    "newframe['frequency'] = MAX_ERRORS\n",
    "idata.drop(idata.loc[idata['frequency'] == MAX_ERRORS].index, inplace=True)\n",
    "idata = pd.concat([idata, newframe], ignore_index=True)\n",
    "\n",
    "# average over the experiments across error types\n",
    "def summary(group):\n",
    "    d = {}\n",
    "    stats = ds.describe(group.value)\n",
    "    d['mean'] = stats.loc['mean', 'value']\n",
    "    d['std'] = stats.loc['std_err', 'value']\n",
    "    return pd.Series(d, index=['mean', 'std'])\n",
    "df_aggregate = idata.groupby(['type', 'frequency'], as_index=False).apply(summary, include_groups=False)\n",
    "\n",
    "\n",
    "fig = pg.Figure()\n",
    "\n",
    "for error_type in ['substitutions', 'insertions', 'deletions']:\n",
    "\n",
    "    this_data = df_aggregate.loc[df_aggregate['type'] == error_type].copy()\n",
    "    fig.add_trace(\n",
    "        pg.Bar(\n",
    "            x=this_data['frequency'],\n",
    "            y=this_data['mean'],\n",
    "            marker_color=error_colors[error_type]\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    template='simple_white',\n",
    "    height=200,\n",
    "    width=400,\n",
    "    showlegend=False,\n",
    "    barmode='group',\n",
    "    margin=dict(l=50, r=0, t=5, b=0),\n",
    "    font_family=\"Inter\",\n",
    "    legend_font_size=28/3,\n",
    ")\n",
    "\n",
    "ticktext = list(map(str, range(0, MAX_ERRORS+1)))\n",
    "ticktext[-1] += '+'\n",
    "\n",
    "fig.update_xaxes(\n",
    "    title=\"Number of errors in read\",\n",
    "    range=[-0.5, MAX_ERRORS+0.5],\n",
    "    tickmode = 'array',\n",
    "    tickvals = list(range(0, MAX_ERRORS+1)),\n",
    "    ticktext = ticktext,\n",
    ")\n",
    "\n",
    "fig.update_yaxes(\n",
    "    title=\"Fraction of reads\", \n",
    "    tickformat=\",.0%\", \n",
    "    range=[0, 0.65], \n",
    "    dtick=0.25,\n",
    "    title_font_family=\"Inter\",\n",
    "    title_font_size=28/3, \n",
    "    tickfont_size=28/3\n",
    ")\n",
    "\n",
    "fig = plotting.standardize_plot(fig)\n",
    "fig.show()\n",
    "fig.write_image(\"./SI_figures/error_distribution_by_read.svg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "standard-3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
