{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import itertools\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data from Data Sheet for beads\n",
    "\n",
    "Data from Beckman Coulter for AMPure XP beads (https://media.beckman.com/-/media/pdf-assets/data-sheets/genomics-data-sheet-ampure-xp-purification-and-clean-up.pdf) digitized with WebPlotDigitizer (https://apps.automeris.io/wpd/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_csv('wpd_datasets.csv', header=[0,1], skipinitialspace=True)\n",
    "\n",
    "full_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert multilevel columns to long format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for i in range(len(full_df.columns.levels[0])//2):\n",
    "    idf = full_df.iloc[:, 2*i:2*(i+1)].copy()\n",
    "    name = idf.columns[0][0]\n",
    "    idf.columns = idf.columns.droplevel(0)\n",
    "    idf.dropna(inplace=True)\n",
    "    idf['group'] = name\n",
    "    dfs.append(idf)\n",
    "long_df = pd.concat(dfs).reset_index(drop=True)\n",
    "\n",
    "long_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate transform for x-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_points = long_df[long_df.group == \"xaxis\"].copy().sort_values(by=\"X\").X.values\n",
    "real_points = [35, 50, 100, 150, 200, 300, 400, 500, 600, 700]\n",
    "\n",
    "xvals = np.linspace(35, 700, 1000)\n",
    "yinterp = np.interp(xvals, axis_points, real_points)\n",
    "fig = px.scatter(x=xvals, y=yinterp)\n",
    "fig.add_trace(go.Scatter(x=axis_points, y=real_points, mode='markers', name='Real points'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform x-data and clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df = long_df[long_df.group != \"xaxis\"].copy()\n",
    "\n",
    "# clip signal (Y) to zero\n",
    "analysis_df['signal'] = analysis_df.Y.clip(lower=0)\n",
    "# transform X to real size\n",
    "analysis_df['size'] = np.interp(analysis_df.X, axis_points, real_points)\n",
    "\n",
    "# drop uninteresting region\n",
    "analysis_df.drop(analysis_df[analysis_df['size'] <= 40].index, inplace=True)\n",
    "analysis_df.drop(analysis_df[analysis_df['size'] >= 700].index, inplace=True)\n",
    "\n",
    "px.line(analysis_df, x='size', y='signal', color='group').show()\n",
    "analysis_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolate to equal grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = np.linspace(40, 700, 100)\n",
    "def interp(df):\n",
    "    return pd.Series(np.interp(x_vals, np.array(df[\"size\"]), np.array(df[\"signal\"])))\n",
    "\n",
    "interp_df = analysis_df.groupby('group').apply(interp).T\n",
    "interp_df['size'] = x_vals\n",
    "\n",
    "interp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize signal to Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_df[['norm_0.6x', 'norm_0.7x', 'norm_0.9x', 'norm_1.8x']] = interp_df[['0.6x', '0.7x', '0.9x', '1.8x']].div(interp_df['Input'], axis=0)\n",
    "\n",
    "# clip signal (Y) to one\n",
    "interp_df[['norm_0.6x', 'norm_0.7x', 'norm_0.9x', 'norm_1.8x']] = interp_df[['norm_0.6x', 'norm_0.7x', 'norm_0.9x', 'norm_1.8x']].clip(upper=1)\n",
    "\n",
    "px.line(interp_df, x='size', y=['norm_0.6x', 'norm_0.7x', 'norm_0.9x', 'norm_1.8x']).show()\n",
    "interp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit piecewise linear function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recovery_model(x, start, stop):\n",
    "    if stop < start: return np.zeros_like(x)\n",
    "    y = np.zeros_like(x)\n",
    "    y[x >= stop] = 1\n",
    "    y[(x > start) & (x < stop)] = np.linspace(0, 1, np.sum((x > start) & (x < stop)))\n",
    "    return y\n",
    "\n",
    "# get all possible combinations of start and stop points\n",
    "combinations = itertools.product(*[np.arange(40, 700, 10)]*2)\n",
    "combinations = [c for c in combinations if c[0] < c[1]]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for exp in ['0.6x', '0.7x', '0.9x', '1.8x']:\n",
    "    df = interp_df[['size', f'norm_{exp}']].copy()\n",
    "    guess_start = df['size'][df[f'norm_{exp}'] < 0.01].max()\n",
    "    guess_stop = df['size'][df[f'norm_{exp}'] > 0.99].min()\n",
    "    idf = df[(df['size'] > max(40, guess_start-40)) & (df['size'] < min(700, guess_stop+40))].copy()\n",
    "\n",
    "    values = []\n",
    "    for combination in combinations:\n",
    "        y_pred = recovery_model(idf['size'], *combination)\n",
    "        values.append(np.sum((idf[f'norm_{exp}'] - y_pred)**2))\n",
    "    params = combinations[np.argmin(values)]\n",
    "    results[exp] = {\"fit_range\": (idf['size'].min(), idf['size'].max()), \"params\": params}\n",
    "    print(f\"Best combination for {exp}: {params} with {values[np.argmin(values)]:.5f} loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = {\n",
    "    'norm_0.6x': '#e41a1c', \n",
    "    'norm_0.7x': '#377eb8', \n",
    "    'norm_0.9x': '#984ea3', \n",
    "    'norm_1.8x': '#ff7f00'\n",
    "}\n",
    "\n",
    "fig = px.line(\n",
    "    interp_df, \n",
    "    x='size', \n",
    "    y=['norm_0.6x', 'norm_0.7x', 'norm_0.9x', 'norm_1.8x'],\n",
    "    color_discrete_map=colormap,\n",
    ")\n",
    "\n",
    "\n",
    "for exp in ['0.6x', '0.7x', '0.9x', '1.8x']:\n",
    "    data = results[exp]\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=np.linspace(*data[\"fit_range\"], 100),\n",
    "        y=recovery_model(np.linspace(*data[\"fit_range\"], 100), *data[\"params\"]), \n",
    "        mode='lines', \n",
    "        line_dash='dot',\n",
    "        line_color='black',\n",
    "    ))\n",
    "\n",
    "    fig.add_annotation(\n",
    "        x=0.875*data[\"fit_range\"][1],\n",
    "        y=0.7,\n",
    "        text=f\"{exp}\",\n",
    "        showarrow=False,\n",
    "        font_color=colormap[f\"norm_{exp}\"],\n",
    "    )\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    width=300,\n",
    "    height=200,\n",
    "    showlegend=False,\n",
    "    margin=dict(l=0, r=10, t=10, b=0),\n",
    ")\n",
    "fig.update_xaxes(title_text='Size', range=[40, 650])\n",
    "fig.update_yaxes(title_text='Normalized signal', range=[0, 1.01])\n",
    "\n",
    "fig = plotting.standardize_plot(fig)\n",
    "fig.write_image(\"figures/recovery_model.svg\")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "standard-3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
